{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/pratul007/starbucks-dataset-review-with-meta-llama-7b-model?scriptVersionId=143627339\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","source":" # Installation","metadata":{}},{"cell_type":"code","source":"# Install necessary packages\n!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu117 --upgrade\n!pip install langchain einops accelerate transformers bitsandbytes scipy\n!pip install xformers sentencepiece\n!pip install llama-index llama_hub --upgrade\n!pip install sentence-transformers\n!pip install pypdf2\n!pip install git+https://github.com/huggingface/transformers.git@main --quiet\n!pip install git+https://github.com/huggingface/accelerate@main --quiet\n!pip install tensor_parallel","metadata":{"_uuid":"bff4e4f1-3663-41a9-8dc1-0a26fc08f5f9","_cell_guid":"6bd017b7-4cf7-4a5a-9e03-b4e70ba1df9a","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-09-20T10:00:31.884838Z","iopub.execute_input":"2023-09-20T10:00:31.885292Z","iopub.status.idle":"2023-09-20T10:05:40.130489Z","shell.execute_reply.started":"2023-09-20T10:00:31.885242Z","shell.execute_reply":"2023-09-20T10:05:40.129251Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Libraries","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport torch\nfrom transformers import AutoTokenizer, AutoModelForCausalLM\nfrom llama_index import VectorStoreIndex, ServiceContext, set_global_service_context, Document\nfrom llama_index.llms import HuggingFaceLLM\nfrom llama_index.embeddings import LangchainEmbedding\nfrom langchain.embeddings.huggingface import HuggingFaceEmbeddings\nimport warnings \nwarnings.filterwarnings(\"ignore\")","metadata":{"_uuid":"bff4e4f1-3663-41a9-8dc1-0a26fc08f5f9","_cell_guid":"6bd017b7-4cf7-4a5a-9e03-b4e70ba1df9a","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-09-20T10:05:54.645114Z","iopub.execute_input":"2023-09-20T10:05:54.645497Z","iopub.status.idle":"2023-09-20T10:06:04.649989Z","shell.execute_reply.started":"2023-09-20T10:05:54.645463Z","shell.execute_reply":"2023-09-20T10:06:04.649022Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Converting CSV file into LLAMA-Index docmument","metadata":{}},{"cell_type":"code","source":"# Load the CSV into a Pandas DataFrame\ndf = pd.read_csv(\"/kaggle/input/starbucks-reviews-dataset/reviews_data.csv\")\n\n# Convert the DataFrame content into a format suitable for Llama\ndocuments = [\n    Document(\n        text=\" \".join([f\"{col}: {value}\" for col, value in zip(df.columns, row.astype(str))]),\n        metadata={\"row_num\": idx}\n    ) \n    for idx, row in df.iterrows()\n]","metadata":{"_uuid":"bff4e4f1-3663-41a9-8dc1-0a26fc08f5f9","_cell_guid":"6bd017b7-4cf7-4a5a-9e03-b4e70ba1df9a","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-09-20T10:06:57.989432Z","iopub.execute_input":"2023-09-20T10:06:57.990068Z","iopub.status.idle":"2023-09-20T10:06:58.238109Z","shell.execute_reply.started":"2023-09-20T10:06:57.990031Z","shell.execute_reply":"2023-09-20T10:06:58.237093Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Llama setup","metadata":{}},{"cell_type":"code","source":"# Llama setup\nmodel_name = '/kaggle/input/llama-2/pytorch/7b-chat-hf/1'\ntokenizer = AutoTokenizer.from_pretrained(model_name)\nmodel = AutoModelForCausalLM.from_pretrained(model_name,device_map='auto',torch_dtype=torch.float16)","metadata":{"_uuid":"bff4e4f1-3663-41a9-8dc1-0a26fc08f5f9","_cell_guid":"6bd017b7-4cf7-4a5a-9e03-b4e70ba1df9a","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-09-20T10:07:32.803257Z","iopub.execute_input":"2023-09-20T10:07:32.80363Z","iopub.status.idle":"2023-09-20T10:10:31.689464Z","shell.execute_reply.started":"2023-09-20T10:07:32.8036Z","shell.execute_reply":"2023-09-20T10:10:31.688465Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"system_prompt = \"\"\"<s>[INST] <<SYS>>\nYou are a helpful, respectful, and honest assistant. Always answer as helpfully as possible, \nwhile being safe. Your answers should not include any harmful, unethical, racist, sexist, toxic, dangerous, or illegal content. \nPlease ensure that your responses are socially unbiased and positive in nature. \nIf a question does not make any sense, or is not factually coherent, explain why instead of answering something not correct. \nIf you don't know the answer to a question, please don't share false information. \nYour goal is to provide answers relating to the Starbucks customer review from the csv file.<</SYS>>\"\"\"\n\nquery_wrapper_prompt = \"{query_str}\"\n\nllm = HuggingFaceLLM(\n    context_window=4098,\n    max_new_tokens=256,\n    system_prompt=system_prompt,\n    query_wrapper_prompt=query_wrapper_prompt,\n    model=model,\n    tokenizer=tokenizer\n)\n\nembeddings = LangchainEmbedding(HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\"))\nservice_context = ServiceContext.from_defaults(chunk_size=4098, llm=llm, embed_model=embeddings)\nset_global_service_context(service_context)\n\n# Create an index using the DataFrame's content\nindex = VectorStoreIndex.from_documents(documents)\nquery_engine = index.as_query_engine()\n\ndef generate_response(query_text):\n    input_tokens = tokenizer(query_text, return_tensors=\"pt\").to(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    output = model.generate(**input_tokens)\n    response = tokenizer.decode(output[0], skip_special_tokens=True)\n    return response","metadata":{"_uuid":"bff4e4f1-3663-41a9-8dc1-0a26fc08f5f9","_cell_guid":"6bd017b7-4cf7-4a5a-9e03-b4e70ba1df9a","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-09-20T10:10:55.407129Z","iopub.execute_input":"2023-09-20T10:10:55.407551Z","iopub.status.idle":"2023-09-20T10:11:09.873621Z","shell.execute_reply.started":"2023-09-20T10:10:55.407521Z","shell.execute_reply":"2023-09-20T10:11:09.87261Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Sample Queries and Responses","metadata":{}},{"cell_type":"code","source":"# Sample Queries\nqueries = [\n\"What is the overall sentiment of the Starbucks customer reviews?\",\n\"Which Starbucks product has the highest number of positive reviews?\",\n\"How do customers feel about the pricing at Starbucks?\",\n\"Which location has the highest average rating for Starbucks reviews?\",\n\"Are there any recurring themes or keywords in negative reviews (rating 1 or 2)?\",\n\"How have Starbucks reviews trended over time? Are they improving or declining?\",\n\"Which reviewers have posted multiple reviews, and what is their general sentiment?\",\n\"Are there any correlations between the reviewer's location and their rating?\",\n\"What percentage of reviews have associated images, and do these reviews have a higher or lower average rating?\",\n\"Which month or season has the highest number of reviews posted for Starbucks?\",\n]\n\nfor query in queries:\n    print(f\"Question: {generate_response(query)}\")\n    print(\"=\" * 100)","metadata":{"_uuid":"bff4e4f1-3663-41a9-8dc1-0a26fc08f5f9","_cell_guid":"6bd017b7-4cf7-4a5a-9e03-b4e70ba1df9a","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-09-20T10:22:42.520893Z","iopub.execute_input":"2023-09-20T10:22:42.522005Z","iopub.status.idle":"2023-09-20T10:25:51.083882Z","shell.execute_reply.started":"2023-09-20T10:22:42.521954Z","shell.execute_reply":"2023-09-20T10:25:51.082103Z"},"trusted":true},"execution_count":null,"outputs":[]}]}