{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Loading Dependencies","metadata":{}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.metrics.pairwise import cosine_similarity\nimport spacy\n!python -m spacy download en_core_web_md\nnlp = spacy.load('en_core_web_md')\n\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-04-25T18:32:37.730637Z","iopub.execute_input":"2023-04-25T18:32:37.730954Z","iopub.status.idle":"2023-04-25T18:33:32.421745Z","shell.execute_reply.started":"2023-04-25T18:32:37.730925Z","shell.execute_reply":"2023-04-25T18:33:32.420433Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Importing and Cleaning Dataset","metadata":{}},{"cell_type":"code","source":"df  = pd.read_csv('/kaggle/input/tmdb-15000-movies-dataset-with-credits/movie_data.csv', lineterminator=\"\\n\")","metadata":{"execution":{"iopub.status.busy":"2023-04-25T18:33:32.424450Z","iopub.execute_input":"2023-04-25T18:33:32.425520Z","iopub.status.idle":"2023-04-25T18:33:39.130399Z","shell.execute_reply.started":"2023-04-25T18:33:32.425472Z","shell.execute_reply":"2023-04-25T18:33:39.129340Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(df.head())\nprint(df.info())\nprint(df.describe())","metadata":{"execution":{"iopub.status.busy":"2023-04-25T18:33:39.131910Z","iopub.execute_input":"2023-04-25T18:33:39.132286Z","iopub.status.idle":"2023-04-25T18:33:39.200785Z","shell.execute_reply.started":"2023-04-25T18:33:39.132247Z","shell.execute_reply":"2023-04-25T18:33:39.199571Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Check for missing values\nprint(df.isnull().sum())\n\n\n# Drop duplicates\ndf.drop_duplicates(inplace=True)","metadata":{"execution":{"iopub.status.busy":"2023-04-25T18:33:39.203634Z","iopub.execute_input":"2023-04-25T18:33:39.204238Z","iopub.status.idle":"2023-04-25T18:33:40.020127Z","shell.execute_reply.started":"2023-04-25T18:33:39.204186Z","shell.execute_reply":"2023-04-25T18:33:40.019073Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Dropping for missing values\nprint(df.dropna(inplace=True))","metadata":{"execution":{"iopub.status.busy":"2023-04-25T18:33:40.021840Z","iopub.execute_input":"2023-04-25T18:33:40.022208Z","iopub.status.idle":"2023-04-25T18:33:40.044856Z","shell.execute_reply.started":"2023-04-25T18:33:40.022166Z","shell.execute_reply":"2023-04-25T18:33:40.043703Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Drop unnecessary columns\ndf = df.drop(['Unnamed: 0', 'backdrop_path', 'poster_path', 'video'], axis=1)\n\n# Convert release_date to datetime format\ndf['release_date'] = pd.to_datetime(df['release_date'], errors='coerce')\n\n# Replace missing values with empty strings\ndf = df.fillna('')","metadata":{"execution":{"iopub.status.busy":"2023-04-25T18:33:40.046522Z","iopub.execute_input":"2023-04-25T18:33:40.046972Z","iopub.status.idle":"2023-04-25T18:33:40.073174Z","shell.execute_reply.started":"2023-04-25T18:33:40.046933Z","shell.execute_reply":"2023-04-25T18:33:40.072158Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Stopwords using TF-IDF","metadata":{}},{"cell_type":"code","source":"# Create a TF-IDF vectorizer\ntfidf = TfidfVectorizer(stop_words='english')\n\n# Compute TF-IDF matrix\ntfidf_matrix = tfidf.fit_transform(df['overview'])\n\n# Compute cosine similarity matrix\ncosine_sim = cosine_similarity(tfidf_matrix, tfidf_matrix)","metadata":{"execution":{"iopub.status.busy":"2023-04-25T18:33:40.074721Z","iopub.execute_input":"2023-04-25T18:33:40.075124Z","iopub.status.idle":"2023-04-25T18:33:43.245229Z","shell.execute_reply.started":"2023-04-25T18:33:40.075086Z","shell.execute_reply":"2023-04-25T18:33:43.244144Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_recommendations(title, cosine_sim=cosine_sim, df=df):\n    # Get the index of the movie that matches the title\n    idx = df[df['title'] == title].index[0]\n\n    # Get the pairwise similarity scores\n    sim_scores = list(enumerate(cosine_sim[idx]))\n\n    # Sort the movies based on the similarity scores\n    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n\n    # Get the top 10 most similar movies\n    sim_scores = sim_scores[1:11]\n    movie_indices = [i[0] for i in sim_scores]\n    return df['title'].iloc[movie_indices]\n","metadata":{"execution":{"iopub.status.busy":"2023-04-25T18:33:43.246550Z","iopub.execute_input":"2023-04-25T18:33:43.246949Z","iopub.status.idle":"2023-04-25T18:33:43.254929Z","shell.execute_reply.started":"2023-04-25T18:33:43.246911Z","shell.execute_reply":"2023-04-25T18:33:43.253839Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Recommendation","metadata":{}},{"cell_type":"code","source":"get_recommendations('The Dark Knight')","metadata":{"execution":{"iopub.status.busy":"2023-04-25T18:33:43.256470Z","iopub.execute_input":"2023-04-25T18:33:43.257245Z","iopub.status.idle":"2023-04-25T18:33:43.284045Z","shell.execute_reply.started":"2023-04-25T18:33:43.257207Z","shell.execute_reply":"2023-04-25T18:33:43.282846Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Improving Recommendation","metadata":{}},{"cell_type":"code","source":"# Import necessary libraries\nimport spacy\nnlp = spacy.load('en_core_web_md')\n\n# Define a function to preprocess text data using Spacy\ndef preprocess(text):\n    doc = nlp(text)\n    return ' '.join([token.lemma_ for token in doc if not token.is_stop and token.is_alpha])\n\n# Preprocess the overview column\ndf['overview_processed'] = df['overview'].apply(preprocess)\n\n# Create a new TF-IDF vectorizer with the preprocessed text\ntfidf_processed = TfidfVectorizer(stop_words='english')\ntfidf_matrix_processed = tfidf_processed.fit_transform(df['overview_processed'])\n\n# Compute cosine similarity matrix with the preprocessed text\ncosine_sim_processed = cosine_similarity(tfidf_matrix_processed, tfidf_matrix_processed)\n\n# Use the new cosine similarity matrix to get recommendations\nget_recommendations('The Dark Knight', cosine_sim_processed, df)","metadata":{"execution":{"iopub.status.busy":"2023-04-25T18:33:43.287592Z","iopub.execute_input":"2023-04-25T18:33:43.288323Z","iopub.status.idle":"2023-04-25T18:36:38.515895Z","shell.execute_reply.started":"2023-04-25T18:33:43.288292Z","shell.execute_reply":"2023-04-25T18:36:38.514764Z"},"trusted":true},"execution_count":null,"outputs":[]}]}