{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/pratul007/porsche-911-data-analysis-query-with-llama-2-7b?scriptVersionId=143623015\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"# Install necessary packages\n!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu117 --upgrade\n!pip install langchain einops accelerate transformers bitsandbytes scipy\n!pip install xformers sentencepiece\n!pip install llama-index llama_hub --upgrade\n!pip install sentence-transformers\n!pip install pypdf2\n!pip install git+https://github.com/huggingface/transformers.git@main --quiet\n!pip install git+https://github.com/huggingface/accelerate@main --quiet\n!pip install tensor_parallel","metadata":{"_uuid":"bff4e4f1-3663-41a9-8dc1-0a26fc08f5f9","_cell_guid":"6bd017b7-4cf7-4a5a-9e03-b4e70ba1df9a","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-09-20T09:28:22.338077Z","iopub.execute_input":"2023-09-20T09:28:22.338756Z","iopub.status.idle":"2023-09-20T09:33:16.938658Z","shell.execute_reply.started":"2023-09-20T09:28:22.338719Z","shell.execute_reply":"2023-09-20T09:33:16.937407Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport torch\nfrom transformers import AutoTokenizer, AutoModelForCausalLM\nfrom llama_index import VectorStoreIndex, ServiceContext, set_global_service_context, Document\nfrom llama_index.llms import HuggingFaceLLM\nfrom llama_index.embeddings import LangchainEmbedding\nfrom langchain.embeddings.huggingface import HuggingFaceEmbeddings\nimport warnings \nwarnings.filterwarnings(\"ignore\")","metadata":{"_uuid":"bff4e4f1-3663-41a9-8dc1-0a26fc08f5f9","_cell_guid":"6bd017b7-4cf7-4a5a-9e03-b4e70ba1df9a","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-09-20T09:33:16.941328Z","iopub.execute_input":"2023-09-20T09:33:16.941783Z","iopub.status.idle":"2023-09-20T09:33:25.809345Z","shell.execute_reply.started":"2023-09-20T09:33:16.941737Z","shell.execute_reply":"2023-09-20T09:33:25.808389Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Load the CSV into a Pandas DataFrame\ndf = pd.read_csv(\"/kaggle/input/every-porsche-911/porsche_911.csv\")\n\n# Convert the DataFrame content into a format suitable for Llama\ndocuments = [\n    Document(\n        text=\" \".join([f\"{col}: {value}\" for col, value in zip(df.columns, row.astype(str))]),\n        metadata={\"row_num\": idx}\n    ) \n    for idx, row in df.iterrows()\n]","metadata":{"_uuid":"bff4e4f1-3663-41a9-8dc1-0a26fc08f5f9","_cell_guid":"6bd017b7-4cf7-4a5a-9e03-b4e70ba1df9a","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-09-20T09:33:25.810605Z","iopub.execute_input":"2023-09-20T09:33:25.813208Z","iopub.status.idle":"2023-09-20T09:33:25.934404Z","shell.execute_reply.started":"2023-09-20T09:33:25.813178Z","shell.execute_reply":"2023-09-20T09:33:25.933479Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Llama setup\nmodel_name = '/kaggle/input/llama-2/pytorch/7b-chat-hf/1'\ntokenizer = AutoTokenizer.from_pretrained(model_name)\nmodel = AutoModelForCausalLM.from_pretrained(model_name,device_map='auto',torch_dtype=torch.float16)","metadata":{"_uuid":"bff4e4f1-3663-41a9-8dc1-0a26fc08f5f9","_cell_guid":"6bd017b7-4cf7-4a5a-9e03-b4e70ba1df9a","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-09-20T09:33:25.936664Z","iopub.execute_input":"2023-09-20T09:33:25.937078Z","iopub.status.idle":"2023-09-20T09:36:08.581859Z","shell.execute_reply.started":"2023-09-20T09:33:25.937044Z","shell.execute_reply":"2023-09-20T09:36:08.58093Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"system_prompt = \"\"\"<s>[INST] <<SYS>>\nYou are a helpful, respectful, and honest assistant. Always answer as helpfully as possible, while being safe. Your answers should not include any harmful, unethical, racist, sexist, toxic, dangerous, or illegal content. Please ensure that your responses are socially unbiased and positive in nature. If a question does not make any sense, or is not factually coherent, explain why instead of answering something not correct. If you don't know the answer to a question, please don't share false information. Your goal is to provide answers relating to the car Porsche from the csv.<</SYS>>\"\"\"\n\nquery_wrapper_prompt = \"{query_str}\"\n\nllm = HuggingFaceLLM(\n    context_window=4098,\n    max_new_tokens=256,\n    system_prompt=system_prompt,\n    query_wrapper_prompt=query_wrapper_prompt,\n    model=model,\n    tokenizer=tokenizer\n)\n\nembeddings = LangchainEmbedding(HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\"))\nservice_context = ServiceContext.from_defaults(chunk_size=4098, llm=llm, embed_model=embeddings)\nset_global_service_context(service_context)\n\n# Create an index using the DataFrame's content\nindex = VectorStoreIndex.from_documents(documents)\nquery_engine = index.as_query_engine()\n\ndef generate_response(query_text):\n    input_tokens = tokenizer(query_text, return_tensors=\"pt\").to(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    output = model.generate(**input_tokens)\n    response = tokenizer.decode(output[0], skip_special_tokens=True)\n    return response","metadata":{"_uuid":"bff4e4f1-3663-41a9-8dc1-0a26fc08f5f9","_cell_guid":"6bd017b7-4cf7-4a5a-9e03-b4e70ba1df9a","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-09-20T09:36:31.12343Z","iopub.execute_input":"2023-09-20T09:36:31.124829Z","iopub.status.idle":"2023-09-20T09:36:34.46082Z","shell.execute_reply.started":"2023-09-20T09:36:31.124782Z","shell.execute_reply":"2023-09-20T09:36:34.45978Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Sample Queries\nqueries = [\n    \"Describe the fuel efficiency trends in Porsche 911 models from 2010 to 2020.\",\n    \"Which models of the Porsche 911 have a rear-wheel-drive powertrain architecture?\",\n    \"What is the most relevant year and why for the Porsche 911 dataset?\"\n]\n\nfor query in queries:\n    print(f\"Question: {query}\")\n    print(f\"Response: {generate_response(query)}\")\n    print(\"-\" * 50)","metadata":{"_uuid":"bff4e4f1-3663-41a9-8dc1-0a26fc08f5f9","_cell_guid":"6bd017b7-4cf7-4a5a-9e03-b4e70ba1df9a","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-09-20T09:36:37.132027Z","iopub.execute_input":"2023-09-20T09:36:37.134682Z","iopub.status.idle":"2023-09-20T09:38:19.645309Z","shell.execute_reply.started":"2023-09-20T09:36:37.134644Z","shell.execute_reply":"2023-09-20T09:38:19.644255Z"},"trusted":true},"execution_count":null,"outputs":[]}]}